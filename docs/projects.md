# My Projects

## [Battleship Solvers](battleship.md)

I leveraged 3 different methods to attempt to create optimal battleship strategies and attempted to pit them against each other. 
 
![Screenshot](/assets/battlefieldstats.gif){align=right ; style="height:200px;width:200px"}


 1. Bayesian Sampling of board configurations
 2. Naive Reinforcement learning with a Tensorflow Neural Network
 3. Using an Advantage Actor Critic (A2C) setup to perform Deep Reinforcement Learning

[Read more](battleship.md) or [Find on Github](https://www.github.com/calebdame/Battleship)

## [Fake Tweet Generation](twitter.md)

![Screenshot](/assets/twitter.png){align=right ; style="height:138px;width:335px"}

Using years worth of tweets from various news outlets (CNN, BBC, FOX), I use a Markov Chain crafted in an effort to preserve grammar to generate fake headlines that can sound anywhere from ludicrous to plausible.

Some of the more interesting examples: 
### Fox News
    Obama announces sanctions over his son
    Polygamist Sect Working on Missile Defense Shift
    Giuliani offered vaccine overseas trip
    Mikhail Gorbachev Looks Like Ninjas Targeted Liberals on America GOPDebate
    Chinese Quake Destroyed in bathroom

### CNN
    Trump congratulated the worst possible graves resold plots
    The President Jimmy Fallon resigns after moving out
    The whistleblower says Joe Biden s first presidential inaugural speech
    Sarah Sanders stands at the average resale clothing line against Patrick Mahomes' verified account
    Investigators with Hillary Clinton Donald Trump ripped Sen. Joe Biden on the end to come

### BBC
    Pakistan overcame the first chairman Ben in war-torn areas
    Bin Laden Taliban leader to buy new cap on alcohol-related anti-social behaviour
    The first civil nuclear weapons seized by mistake by 2030
    Police in the country 's government is five newborn babies
    Venezuela's north-western Pakistani men are arrested on the Indian court

[Read More](twitter.md) or [Find on Github](https://www.github.com/calebdame/TwitterBot)

## [An LSTMozart](audio.md)

An RNN-LSTM model is used to learn how to play Mozart sonatas, being trained to predict the time of the beginning of a note, the duration, and the frequenc(y/ies) of the next note(s).

Built in Pytorch, it is a multi-class / multi-label model that simultaneously predicts all the next note's characteristics.  Below is a very elegant schema depicting the network's architecture.

### Network Architecture

```

                     INPUT
                       |
          ____LSTM Layers Output____
         /             |            \
     4 layers      3 layers      4 layers
     w/ Relu       w/ Relu       w/ Relu
        |              |             |
      Offset   --->  Concat  <---  Length
     Softmax           |           Softmax
        |          3 layers          |
        |          w/ Relu           |
        |              |             |
        |            Note            |
        |           Sigmoid          |
        |              |             |   
         \__________Concat__________/
                       |
                    OUTPUT

```


[Read More](music.md)   Listen to an [Example Song](https://github.com/calebdame/LSTMusic/raw/main/example_song.mid) generated by my code [on Github](https://github.com/calebdame/LSTMusic)  

<!-- ## Algorithms to Improve Record-Linking Classification


[Check it out](record.md)

## Unsupervised Learning on Strings Without Vectorization


[Check it out](clustering.md)

## Desktop GUI Crystalline Analysis


[Check it out](magplot.md) -->